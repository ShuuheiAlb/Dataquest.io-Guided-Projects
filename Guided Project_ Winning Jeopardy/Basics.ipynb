{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Guided Project: Winning Jeopardy\n",
    "\n",
    "Goal: Analyzing winning patterns inside data about Jeopardy.\n",
    "\n",
    "The dataset `jeopardy.csv` can be accessed from [this Reddit post by trexmatt](https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Introduction\n",
    "\n",
    "We load the file `jeopardy.csv` and print the details about its shape, columns, and first five rows. Apparently there are some column names with leading/training spaces, so we removed their spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape: (19999, 7)\n",
      "Columns initially:\n",
      "['Show Number' ' Air Date' ' Round' ' Category' ' Value' ' Question'\n",
      " ' Answer']\n",
      "Data format:\n",
      "Show Number     int64\n",
      " Air Date      object\n",
      " Round         object\n",
      " Category      object\n",
      " Value         object\n",
      " Question      object\n",
      " Answer        object\n",
      "dtype: object\n",
      "First five rows:\n",
      "   Show Number    Air Date      Round                         Category  Value  \\\n",
      "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
      "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
      "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
      "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
      "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
      "\n",
      "                                            Question      Answer  \n",
      "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
      "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
      "2  The city of Yuma in this state has a record av...     Arizona  \n",
      "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
      "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  \n",
      "Columns after:\n",
      "['Show Number' 'Air Date' 'Round' 'Category' 'Value' 'Question' 'Answer']\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "print(\"Shape: \" + str(jeopardy.shape))\n",
    "print(\"Columns initially:\")\n",
    "print(jeopardy.columns.values)\n",
    "print(\"Data format:\")\n",
    "print(jeopardy.dtypes)\n",
    "print(\"First five rows:\")\n",
    "print(jeopardy.head())\n",
    "\n",
    "jeopardy.columns = [s.strip() for s in jeopardy.columns.values]\n",
    "print(\"Columns after:\")\n",
    "print(jeopardy.columns.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Normalizing Functions\n",
    "\n",
    "We want to normalize strings in the question and answer columns, by removing punctuations and lowercasing. We consider the edge case of _No._ as in _No. 1_, _No. 2_, etc; since it cannot be differentiated from _no_ as in _yes or no_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                      Clean Question    Clean Answer\n",
      "0  for the last 8 years of his life galileo was u...      copernicus\n",
      "1  number 2 1912 olympian football star at carlis...      jim thorpe\n",
      "2  the city of yuma in this state has a record av...         arizona\n",
      "3  in 1963 live on the art linkletter show this c...       mcdonalds\n",
      "4  signer of the dec of indep framer of the const...      john adams\n",
      "5  in the title of an aesop fable this insect sha...         the ant\n",
      "6  built in 312 bc to link rome  the south of ita...  the appian way\n",
      "7  number 8 30 steals for the birmingham barons 2...  michael jordan\n",
      "8  in the winter of 197172 a record 1122 inches o...      washington\n",
      "9  this housewares store was named for the packag...   crate  barrel\n"
     ]
    }
   ],
   "source": [
    "jeopardy[[\"Clean Question\", \"Clean Answer\"]] \\\n",
    "    = jeopardy[[\"Question\", \"Answer\"]].apply(\n",
    "        lambda x : x.str.replace(r\"(N| n)o\\.( [0-9]+)\", r\"\\1umber\\2\") \\\n",
    "                    .str.lower() \\\n",
    "                    .str.replace(r\"[^a-z0-9 ]\", \"\") \\\n",
    "    )\n",
    "print(jeopardy[[\"Clean Question\", \"Clean Answer\"]].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, the entries of `Value` and `Air Date` are of the type `Object (String)` and are not suitable for numerical analysis. We first see their unique values in order to determine what data cleaning methods we should do."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['$400' '$800' '$200' '$600' '$1000' '$2000' '$1200' '$1600' '$100' '$500'\n",
      " '$300' 'None' '$1,000' '$2,000' '$3,000' '$1,500' '$1,200' '$4,000'\n",
      " '$5,000' '$1,800' '$1,400' '$1,600' '$2,500' '$700' '$2,200' '$2,400'\n",
      " '$3,600' '$7,000' '$6,000' '$1,100' '$1,300' '$3,200' '$3,500' '$900'\n",
      " '$2,800' '$1,900' '$3,400' '$10,000' '$3,100' '$8,000' '$2,600' '$3,800'\n",
      " '$2,100' '$5,600' '$4,400' '$4,600' '$4,800' '$7,200' '$12,000' '$7,400'\n",
      " '$9,000' '$5,800' '$4,100' '$2,300' '$10,800' '$3,389' '$1,111' '$7,500'\n",
      " '$2,900' '$5,400' '$6,200' '$3,300' '$4,500' '$6,800' '$1,492' '$4,700'\n",
      " '$3,900' '$5,200' '$1,700' '$2,127' '$2,021' '$1,020' '$750' '$8,200'\n",
      " '$367' '$6,100']\n"
     ]
    }
   ],
   "source": [
    "print(jeopardy[\"Value\"].value_counts().index.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From above, we would like to remove the symbols `\"$\"` and `\",\"` as well as converting `Value`'s string forms into numbers. Meanwhile, we convert `Air Date` into `datetime` form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  400   800   200  1000   600  2000  1200  1600   100   500   300     0\n",
      "  3000  1500  4000  5000  1800  1400  2500   700  2200  3600  2400  7000\n",
      "  6000   900  1300  3500  3200  1100  3400  1900  2800  8000 10000  3100\n",
      "  2600  2100 12000  4600  7200  5600  4400  4800  3800  5200  1492  6800\n",
      "  7500  1700  7400   750  4700  2127  3900  2300  3389  1020  9000  8200\n",
      "  6200 10800  5800  5400  1111   367  4500  4100  2021  3300  2900  6100]\n"
     ]
    }
   ],
   "source": [
    "jeopardy[\"Clean Value\"] = \\\n",
    "    jeopardy[\"Value\"] \\\n",
    "    .str.replace(r\"[$,]\", \"\") \\\n",
    "    .str.replace(\"None\", \"0\") \\\n",
    "    .astype(int)\n",
    "print(jeopardy[\"Clean Value\"].value_counts().index.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "jeopardy[\"Air Date\"] = pd.to_datetime(jeopardy[\"Air Date\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Analyzing Winning Strategies\n",
    "\n",
    "### a. Recycled Questions\n",
    "\n",
    "One type of winning strategies is to study past problems on Jeopardy. It is helpful to measure the chance of a question being repeated, by counting the past questions' shared complex (> 6 characters) words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg occurence level of a complex word on past questions is 0.6900454028691575\n"
     ]
    }
   ],
   "source": [
    "jeopardy.sort_values(by = \"Air Date\", inplace = True)\n",
    "question_overlapped = []\n",
    "terms_repeated = set()\n",
    "for index, row in jeopardy.iterrows():\n",
    "    split_complex_question = [e for e in row[\"Clean Question\"].split() if len(e) >= 6]\n",
    "    tot = 0\n",
    "    for word in split_complex_question:\n",
    "        if word in terms_repeated:\n",
    "            tot += 1\n",
    "        else:\n",
    "            terms_repeated.add(word)\n",
    "    # If the question has no words, append 0 to prevent division by zero\n",
    "    if (len(split_complex_question) == 0):\n",
    "        question_overlapped.append(0)\n",
    "    else:\n",
    "        question_overlapped.append(tot/len(split_complex_question))\n",
    "\n",
    "jeopardy[\"Question Overlapped\"] = question_overlapped\n",
    "print(\"The avg occurence level of a complex word on past questions is\", np.mean(jeopardy[\"Question Overlapped\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chance is nearly $70 \\%$, quite a large one. Although the data we have now is only $10 \\%$ of Jeopardy's entire dataset, it might be worth to prepare for some recycled questions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b. Answers in Questions\n",
    "\n",
    "Another strategy is to deduct the answer directly from the question. We may analyze this by comparing how often an answer's words are contained in its corresponding question."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The avg occurence level of an answer word coinciding with its question is 0.04261219013331619\n"
     ]
    }
   ],
   "source": [
    "def avg_answer_contained(row):\n",
    "    split_question = row[\"Clean Question\"].split()\n",
    "    split_answer = row[\"Clean Answer\"].split()\n",
    "    # Remove the non-significant words such as \"the\", \"a\", \"an\"\n",
    "    split_answer = [e for e in split_answer if e not in [\"the\", \"a\", \"an\"]]\n",
    "    tot = 0\n",
    "    for word in split_answer:\n",
    "        if word in split_question:\n",
    "            tot += 1\n",
    "    # If the answer has no words, returns 0 to prevent division by zero\n",
    "    if (len(split_answer) == 0):\n",
    "        return 0\n",
    "    else:\n",
    "        return tot/len(split_answer)\n",
    "\n",
    "jeopardy[\"Answer in Question\"] = jeopardy.apply(avg_answer_contained, axis = 1)\n",
    "print(\"The avg occurence level of an answer word coinciding with its question is\", np.mean(jeopardy[\"Answer in Question\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The chance is a small $4\\%$, so deducting answers from their questions is not a good strategy here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### c. High vs Low-Value Questions\n",
    "\n",
    "Alternatively, let say we study only the high-value questions (greater or equal to $\\$800$). We will use chi-squared test to identify terms associated with high-value questions. We examine several words from `term_repeated` and assume that expectedly, the count of these words in high-value questions are equal (and similarly for low-value questions).\n",
    "\n",
    "We performed the code `\"chosen_words = list(terms_repeated)[:5]\"` then put the result manually to give consistency (since `terms_repeated` is a set, therefore that line does not always produce the same result)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "measure (0.2688716582048211, 0.6040896796217152)\n",
      "schubert (0.7721754541426672, 0.3795448984353682)\n",
      "prevow (0.7721754541426672, 0.3795448984353682)\n",
      "alphatrack (1.295042460408538, 0.25512076479610835)\n",
      "pawtucket (1.295042460408538, 0.25512076479610835)\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "from scipy.stats import chisquare\n",
    "\n",
    "# Sort jeopardy back\n",
    "jeopardy.sort_index(inplace = True)\n",
    "# Count the proportions of high/low values in the entire dataset\n",
    "is_hi_val = jeopardy[\"Clean Value\"] >= 800\n",
    "hi_val_prop = np.mean(is_hi_val)\n",
    "lo_val_prop = 1 - hi_val_prop\n",
    "\n",
    "# Function to calculate chi-squared values\n",
    "def process_cs (word):\n",
    "    # Count the observed proportions\n",
    "    is_word_in_question = jeopardy[\"Clean Question\"] \\\n",
    "                            .str.split() \\\n",
    "                            .apply(lambda l: word in l)\n",
    "    word_in_highs_count = (is_word_in_question & is_hi_val).sum()\n",
    "    word_in_lows_count = (is_word_in_question & ~is_hi_val).sum()\n",
    "    observed = (word_in_highs_count, word_in_lows_count)\n",
    "    # Expected counts is proportional to the overall ratio of high and low values\n",
    "    expected = (hi_val_prop * np.sum(observed), lo_val_prop * np.sum(observed))\n",
    "    chi_sq_val, p_val = chisquare(observed, expected)\n",
    "    return chi_sq_val, p_val\n",
    "\n",
    "# Pick the words\n",
    "chosen_words = [\"measure\", \"schubert\", \"prevow\", \"alphatrack\", \"pawtucket\"]\n",
    "for word in chosen_words:\n",
    "    print(word, process_cs(word))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "None of the keywords have high chi-squared value, thus not having significant difference in its appearance in high or low-value problems. The sample sizes are also small, so we still need to work on that (putting all `terms_repeated`'s words make the code very slow, so there has to be some )."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 3. Conclusion\n",
    "\n",
    "Soon ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Sketch ....\n",
    "a = '''abbrevs = {}\n",
    "import re\n",
    "for el in jeopardy[\"Clean Question\"]:\n",
    "    for word in re.findall(r\"([A-Za-z]+\\.) [^A-Z]\", el):\n",
    "        if word not in abbrevs:\n",
    "            abbrevs[word] = 1\n",
    "        else:\n",
    "            abbrevs[word] += 1\n",
    "print(sorted(abbrevs.items(), key = lambda x: x[1], reverse = True))'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
